#!/usr/bin/env python3
"""
Test script for Vision Solver and LLM Reasoning components
"""

import sys
import numpy as np
from pathlib import Path

# Add src to path
src_path = Path(__file__).parent / 'src'
sys.path.insert(0, str(src_path))

from src.data.loader import ARCDataLoader
from src.vision.vision_solver import VisionSolver
from src.llm_reasoning.llm_reasoner import LLMReasoner
from src.core.types import Task


def test_vision_solver():
    """Test the vision solver component"""
    print("=== Testing Vision Solver ===")
    
    # Load a sample task
    loader = ARCDataLoader()
    train_tasks = loader.load_training_tasks()
    
    if not train_tasks:
        print("No training tasks available for testing")
        return
    
    # Get first task
    task_data = train_tasks[0]
    
    print(f"Testing with first training task")
    
    # Create vision solver
    vision_solver = VisionSolver()
    
    try:
        # Generate hypotheses
        hypotheses = vision_solver.generate_hypotheses(task_data, max_hypotheses=5)
        
        print(f"Generated {len(hypotheses)} hypotheses:")
        for i, hypothesis in enumerate(hypotheses):
            print(f"  {i+1}. {hypothesis.description} (confidence: {hypothesis.confidence:.3f})")
            print(f"      Generated by: {hypothesis.generated_by}")
            if hypothesis.metadata:
                print(f"      Metadata: {hypothesis.metadata}")
            print()
        
        if hypotheses:
            print("✅ Vision solver working correctly")
        else:
            print("⚠️  Vision solver generated no hypotheses")
    
    except Exception as e:
        print(f"❌ Vision solver error: {e}")
        import traceback
        traceback.print_exc()


def test_llm_reasoner_mock():
    """Test the LLM reasoner component with mock responses"""
    print("=== Testing LLM Reasoner (Mock Mode) ===")
    
    # Load a sample task
    loader = ARCDataLoader()
    train_tasks = loader.load_training_tasks()
    
    if not train_tasks:
        print("No training tasks available for testing")
        return
    
    # Get first task
    task_data = train_tasks[0]
    
    print(f"Testing with first training task")
    
    # Create LLM reasoner (will fail to initialize without API keys)
    llm_reasoner = LLMReasoner(provider="openai", model="gpt-4")
    
    if not llm_reasoner.client:
        print("No LLM client available (expected - no API keys)")
        
        # Test the formatting functions
        try:
            task_context = llm_reasoner._format_task_for_llm(task_data)
            print("✅ Task formatting working correctly")
            print(f"Context length: {len(task_context)} characters")
            print("Sample context (first 500 chars):")
            print(task_context[:500] + "...")
            
            # Test response parsing with mock response
            mock_json_response = '''
            {
                "reasoning": "This task involves rotating the input grid by 90 degrees clockwise.",
                "transformations": [
                    {"operation": "rotate", "parameters": {"angle": 90}}
                ],
                "confidence": 0.85,
                "explanation": "The output is consistently a 90-degree clockwise rotation of the input."
            }
            '''
            
            parsed_response = llm_reasoner._parse_llm_response(mock_json_response)
            if parsed_response:
                print("✅ Response parsing working correctly")
                print(f"Parsed reasoning: {parsed_response.reasoning[:100]}...")
                print(f"Parsed transformations: {parsed_response.transformations}")
                print(f"Parsed confidence: {parsed_response.confidence}")
                
                # Test hypothesis conversion
                hypotheses = llm_reasoner._convert_to_hypotheses(parsed_response, task_data)
                print(f"✅ Generated {len(hypotheses)} hypotheses from mock response")
                for i, hypothesis in enumerate(hypotheses):
                    print(f"  {i+1}. {hypothesis.description} (confidence: {hypothesis.confidence:.3f})")
            else:
                print("❌ Failed to parse mock response")
        
        except Exception as e:
            print(f"❌ LLM reasoner error: {e}")
            import traceback
            traceback.print_exc()
    
    else:
        print("LLM client available - testing live API calls")
        try:
            # Test with real API call (if credentials available)
            hypotheses = llm_reasoner.generate_hypotheses(task_data, max_hypotheses=3)
            
            print(f"Generated {len(hypotheses)} hypotheses:")
            for i, hypothesis in enumerate(hypotheses):
                print(f"  {i+1}. {hypothesis.description} (confidence: {hypothesis.confidence:.3f})")
                if hypothesis.reasoning:
                    print(f"      Reasoning: {hypothesis.reasoning[:100]}...")
                print()
            
            if hypotheses:
                print("✅ LLM reasoner working correctly")
            else:
                print("⚠️  LLM reasoner generated no hypotheses")
        
        except Exception as e:
            print(f"❌ LLM reasoner API error: {e}")


def test_grid_utilities():
    """Test grid utility functions"""
    print("=== Testing Grid Utilities ===")
    
    # Test grid to string conversion
    vision_solver = VisionSolver()
    
    test_grid = [
        [0, 1, 0],
        [1, 2, 1],
        [0, 1, 0]
    ]
    
    try:
        # Test template detection
        templates = vision_solver.shape_templates
        print(f"✅ Loaded {len(templates)} shape templates")
        for name, template in templates.items():
            print(f"  {name}: {template.shape}")
        
        # Test connected components
        test_array = np.array(test_grid)
        objects = vision_solver._find_connected_components(test_array)
        print(f"✅ Found {len(objects)} connected components")
        
        # Test rotation detection
        rotated_grid = np.rot90(test_array)
        is_rotated = vision_solver._grids_are_rotated(test_array, rotated_grid)
        print(f"✅ Rotation detection: {is_rotated}")
        
        # Test reflection detection
        reflected_grid = np.fliplr(test_array)
        is_reflected = vision_solver._grids_are_reflected(test_array, reflected_grid)
        print(f"✅ Reflection detection: {is_reflected}")
        
        # Test color mapping
        color_mapped_grid = test_array.copy()
        color_mapped_grid[color_mapped_grid == 1] = 3
        color_mapping = vision_solver._find_color_mapping(test_array, color_mapped_grid)
        print(f"✅ Color mapping detection: {color_mapping}")
    
    except Exception as e:
        print(f"❌ Grid utilities error: {e}")
        import traceback
        traceback.print_exc()


def main():
    """Run all tests"""
    print("Testing Vision Solver and LLM Reasoner Components")
    print("=" * 60)
    
    test_grid_utilities()
    print()
    
    test_vision_solver()
    print()
    
    test_llm_reasoner_mock()
    print()
    
    print("=" * 60)
    print("All tests completed!")


if __name__ == "__main__":
    main()
